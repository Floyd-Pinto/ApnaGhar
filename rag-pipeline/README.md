# RAG Pipeline for ApnaGhar Real Estate Data

This RAG (Retrieval-Augmented Generation) pipeline is specifically designed for the ApnaGhar real estate platform. It enables intelligent querying of projects, properties, developers, and construction milestones using natural language.

## ğŸ¯ Purpose

Query your real estate data using natural language questions like:

- "Show me 3BHK properties in Bangalore under 1 crore"
- "Which projects by Prestige Estates are completed?"
- "What are the amenities in Whitefield properties?"
- "List all properties with swimming pool and gym"

## ğŸ—ï¸ Architecture

```
CSV Data â†’ Data Loader â†’ Chunking â†’ Embeddings â†’ Vector Store (FAISS) â†’ RAG Search â†’ LLM Response
```

## ğŸ“ Project Structure

```
rag-pipeline/
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ config.py                  # Configuration settings
â”œâ”€â”€ data/                      # CSV data files
â”‚   â”œâ”€â”€ projects.csv          # Project data
â”‚   â”œâ”€â”€ properties.csv        # Property listings
â”‚   â”œâ”€â”€ developers.csv        # Developer information
â”‚   â””â”€â”€ construction_milestones.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # CSV data loading
â”‚   â”œâ”€â”€ embedding.py          # Text chunking & embeddings
â”‚   â”œâ”€â”€ vectorstore.py        # FAISS vector database
â”‚   â”œâ”€â”€ search.py             # RAG search & retrieval
â”‚   â””â”€â”€ query_engine.py       # Real estate specific queries
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_embedding_generation.ipynb
â”‚   â””â”€â”€ 03_rag_testing.ipynb
â”œâ”€â”€ app.py                    # Main application
â””â”€â”€ faiss_store/              # Vector database storage
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd rag-pipeline
pip install -r requirements.txt
```

### 2. Place Your CSV Files

Copy your CSV files to the `data/` directory:

- `projects_rows.csv` â†’ `data/projects.csv`
- `properties_rows.csv` â†’ `data/properties.csv`
- `developers_rows.csv` â†’ `data/developers.csv`
- `construction_milestones_rows.csv` â†’ `data/construction_milestones.csv`

### 3. Build the Vector Store

```bash
python app.py build
```

This will:

- Load all CSV files
- Convert to structured documents
- Generate embeddings
- Create FAISS index
- Save to `faiss_store/`

### 4. Query the Data

```bash
python app.py query "Show me 3BHK properties in Bangalore"
```

Or use the interactive mode:

```bash
python app.py interactive
```

## ğŸ’¡ Example Queries

### Properties

- "Find 2BHK apartments in Mumbai under 80 lakhs"
- "What properties are available in Electronic City?"
- "Show me penthouses with 4 bedrooms"
- "List properties with modular kitchen and wooden flooring"

### Projects

- "Which projects have swimming pool and gym?"
- "Show ongoing projects in Pune"
- "What is the expected completion date for Royal Towers?"
- "List all residential projects in Delhi"

### Developers

- "Tell me about Prestige Estates"
- "Which developers have the highest trust score?"
- "Show projects by verified developers"
- "What is the RERA number for Godrej Properties?"

### Amenities & Features

- "Which projects have tennis court?"
- "Show properties with spacious balcony"
- "List all projects with clubhouse and parking"

## ğŸ”§ Configuration

Edit `config.py` to customize:

```python
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # Sentence transformer model
CHUNK_SIZE = 500                       # Characters per chunk
CHUNK_OVERLAP = 50                     # Overlap between chunks
TOP_K_RESULTS = 5                      # Number of results to retrieve
LLM_MODEL = "gemma2-9b-it"            # Groq LLM model
```

## ğŸ“Š Data Schema

### Projects

- ID, name, city, state, status, amenities, developer, etc.

### Properties

- ID, unit_number, type, bedrooms, price, status, features, etc.

### Developers

- ID, company_name, RERA number, verified status, trust_score

### Construction Milestones

- Phase number, status, completion dates, progress

## ğŸ§ª Testing with Notebooks

### 01_data_exploration.ipynb

- Load and explore CSV data
- Visualize distributions
- Check data quality

### 02_embedding_generation.ipynb

- Test different embedding models
- Analyze chunk sizes
- Visualize embeddings

### 03_rag_testing.ipynb

- Test RAG queries
- Compare results
- Fine-tune parameters

## ğŸ”Œ Integration with Backend

### Django Integration

```python
# In your Django views
from rag_pipeline.src.query_engine import RealEstateRAG

rag = RealEstateRAG()
result = rag.query("3BHK in Bangalore")
```

### API Endpoint

```python
# backend/projects/views.py
@api_view(['POST'])
def rag_search(request):
    query = request.data.get('query')
    rag = RealEstateRAG()
    results = rag.search_and_format(query)
    return Response(results)
```

## ğŸ“ˆ Performance

- **Embedding Generation**: ~2-3 seconds for 9000 properties
- **Query Time**: ~100-200ms per query
- **Index Size**: ~50MB for full dataset
- **RAM Usage**: ~500MB during operation

## ğŸ” Security

- No API keys stored in code
- Use `.env` file for sensitive data
- FAISS index stored locally

## ğŸ¤ Contributing

1. Add new query templates in `query_engine.py`
2. Improve chunking strategies in `embedding.py`
3. Add new data sources in `data_loader.py`

## ğŸ“ License

Same as ApnaGhar project

## ğŸ› Troubleshooting

### Issue: "FAISS index not found"

**Solution**: Run `python app.py build` first

### Issue: "Out of memory"

**Solution**: Reduce `CHUNK_SIZE` in `config.py`

### Issue: "Poor search results"

**Solution**: Increase `TOP_K_RESULTS` or adjust embedding model

## ğŸ“ Support

For issues or questions, check the main ApnaGhar documentation or create an issue.
